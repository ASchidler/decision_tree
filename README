=== UPDATE ===
The folder non_binary contains a complete extended re-implementation. The dependencies are the same as for the main folder.

=== ORIGINAL ===
The code in this repository applies SAT-based local improvement to heuristically computed decision trees, thereby reducing its depth.
It also contains several decision tree encodings and can produce depth/size optimal decision trees.
Our approach is discussed in our paper "SAT-based Decision Tree Learning for Large Data Sets" at AAAI'21, soon to be published.
The exact code used for the experiments can be found at https://doi.org/10.5281/zenodo.4575724

Instances can be found at the UCI Machine Learning repository, how to convert the instances is explained below.
If you require the exact same instances, for reproducibility, comparability or comprehension, please contact us.

Please note that the current state of the code is designed to support our experiments, we will refactor it into user-friendly code in the near future.


DEPENDENCIES

The code requires python 3 and pysat (package python-sat in PIP).

For the experiments we used the glucose solver (https://www.labri.fr/perso/lsimon/glucose/) and the UWrMaxSat solver (
https://github.com/marekpiotrow/UWrMaxSat). The MaxSAT solver is only required for re-running the feature reduction experiment.
The paths to the solvers must be adapted in the sat_tools.py file unless they are in the PATH.
If the ITI scripts are used, iti_runner.py contains a path to ITI (https://www-lrn.cs.umass.edu/iti/index.html)

RUNNING

Given a classification instance in C4.5 format, with an optional test set named .test, a decision tree can be found by running:
runner.py <path-to-instance>

Local improvement can be performed by first preparing the data as described below and then running:
improve/local_improvement.py <id>


DATA

The local improvement code expects an instance with a specific name the data in the folder "datasets":
In "datasets/trees" there should exist a file "<name>.tree" (Weka) or "<name>.iti" (ITI). Note that at the moment
pruned ITI trees can not be parsed, but it is possible for Weka trees.
In "datasets/split" the instance should be present in C4.5 format:
"<name>.names" contains the metadata.
"<name>.data" contains the training data.
"<name>.test" contains the test data.

The dataset is then referred to by an integer that identifies the datasets position in the alphabetically ordered
list among all datasets. This was convenient for the experiments and will be changed in a future refactoring.



EXPERIMENTS

Code for the experiments can be found here: https://doi.org/10.5281/zenodo.4575724
The datasets can be found at the UCI machine learning repository.
The Zenodo repository contains code to convert
